#!/usr/bin/env python3

#
# BDC.
#
# @author  Christopher Barre (christophersimonbarre@gmail.com).
# @version November 2020.

from urllib.request import Request, urlopen
from urllib.error   import URLError, HTTPError

from bs4 import BeautifulSoup

import json
import datetime
import unidecode
import hashlib
import re

def getText(PageScan):
    text = ''
    for p in PageScan.find_all('p'):
        text = text + p.text.strip() + ' '
    return unidecode.unidecode(text).strip()

def getTimestamp(timestamp, format):
    return datetime.datetime.strptime(timestamp, format).isoformat()

def getPage(url, source):
    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'

    req = Request(url,headers={'User-Agent':user_agent})

    try:
        res = urlopen(req)
    except HTTPError as e:
        print('['+source+']','HTTPError:',e.code)
        exit(-1)
    except URLError as e:
        print('['+source+']','URLError:',e.reason)
        exit(-1)
    return BeautifulSoup(res,'html5lib')

def Output(details):
    print(details['docid'])
    print(details['timestamp'])
    print(details['source'])
    print(details['link'])
    print(details['title'])
    print(details['text'])
    print()

def getArticles(newsurl, source):
    soup = getPage(newsurl, source)
    return soup.findAll('article')    
